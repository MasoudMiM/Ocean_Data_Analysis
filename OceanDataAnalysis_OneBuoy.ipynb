{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ocean Wave Data For Stations Recorded by National Data Buoy Center (NDBC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [**Importing Necessary Libraries**](#0)\n",
    "\n",
    "2. [**Data Collection**](#10)\n",
    "\n",
    "3. [**A look at the Data**](#20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Necessary Libraries <a class=\"anchor\" id=\"0\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's install and import the required libraries\n",
    "# Uncomments the following lines in case you don't have the libraries installed on your machine\n",
    "#!conda install -c conda-forge beautifulsoup4 --yes \n",
    "#!conda install -c conda-forge lxml --yes\n",
    "#!conda install -c conda-forge requests --yes\n",
    "#!conda install -c conda-forge folium=0.9 --yes\n",
    "#!conda install -c conda-forge windrose=1.6.7 --yes\n",
    "\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib.request import urlopen, Request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from windrose import WindroseAxes\n",
    "import folium\n",
    "import json\n",
    "from datetime import date, timedelta, datetime\n",
    "# Put figures in the center\n",
    "from IPython.core.display import HTML\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "print('All libraries installed and imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Collection <a class=\"anchor\" id=\"10\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get the list of all the buoys from National Data Buoy Center. To get access to the data, we need to first create an account [here](https://data.planetos.com/datasets/noaa_ndbc_stdmet_stations?utm_source=github&utm_medium=notebook&utm_campaign=ndbc-wavewatch-iii-notebook). Once the account is created, API Key can be found under __Account Setting__. The data set id for National Data Buoy Center (NDBC) Standard Meteorological Data is __noaa_ndbc_stdmet_stations__. This data typically updates every hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we use an API to get Buys' latitude, longitude and names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ hidden\n",
    "APIKey = \n",
    "DatasetID = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_url = 'http://api.planetos.com/v1/datasets/%s/stations?apikey=%s' % (DatasetID, APIKey)\n",
    "request = requests.get(API_url).json() #Request(API_url)\n",
    "Stations = pd.DataFrame(request['station'])\n",
    "\n",
    "df_stations = pd.DataFrame(Stations.columns)\n",
    "for indx, StName in enumerate(Stations.columns):\n",
    "    df_stations.loc[indx,1]=Stations.loc['SpatialExtent'][indx]['coordinates'][0]\n",
    "    df_stations.loc[indx,2]=Stations.loc['SpatialExtent'][indx]['coordinates'][1]\n",
    "\n",
    "df_stations.columns = ['Station_Name','Latitude','Longitude']\n",
    "print('number of stations:',df_stations.shape[0])\n",
    "df_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the data from this API is not complete for each buoy and also have missing columns, we use the National Data Buoy Center website directly at https://www.ndbc.noaa.gov/ to get our information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a list of stations categorized by their owners [here](https://www.ndbc.noaa.gov/to_station.shtml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source=requests.get('https://www.ndbc.noaa.gov/to_station.shtml').text\n",
    "soup = BeautifulSoup(source,'lxml')\n",
    "Owners=[]\n",
    "BuoyData={}\n",
    "\n",
    "for owner in soup.find_all('h4'):\n",
    "    Owners.append(owner.text)\n",
    "for indx,table in enumerate(soup.find_all('pre')):\n",
    "    #print(indx,table.text)\n",
    "    try:\n",
    "        BuoyData[Owners[indx]]=table.text.replace('\\n','').strip()\n",
    "    except:\n",
    "        BuoyData[Owners[indx]]=table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's make all the station names uppercase since they are in lowercase format in the website\n",
    "df_stations['Station_Name']=df_stations['Station_Name'].str.upper()\n",
    "# Now, let's put this data and the data containing the latitudes and longitudes in the same dataframe\n",
    "newlist1=[]\n",
    "newlist2=[]\n",
    "for indx1 in range(df_stations.shape[0]):\n",
    "    for indx2,owner in enumerate(Owners):\n",
    "        if (df_stations.iloc[indx1,0] in BuoyData[owner]):\n",
    "            newlist1.append(owner)\n",
    "            newlist2.append(df_stations.iloc[indx1,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations0=pd.DataFrame({'Station_Name':newlist2,'Owner':newlist1})\n",
    "df_full1=pd.merge(df_stations0, df_stations, on='Station_Name')\n",
    "print('Number of Stations:',df_full1.shape[0])\n",
    "df_full1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuoyLocationPlot2(buoys,MapInput,DataFrameInput,colorm,fill_colorm,Marker=False):\n",
    "    # instantiate a feature group for the buoys in the dataframe\n",
    "    \n",
    "    # loop through and add each to the feature group\n",
    "    for lat, lng, label in zip(DataFrameInput.Longitude, DataFrameInput.Latitude, DataFrameInput.Station_Name):\n",
    "        buoys.add_child(\n",
    "            folium.CircleMarker(\n",
    "                [lat, lng],\n",
    "                radius=6, # define how big you want the circle markers to be\n",
    "                color=colorm,\n",
    "                fill=True,\n",
    "                fill_color=fill_colorm,\n",
    "                fill_opacity=0.8,\n",
    "                popup=label\n",
    "            )\n",
    "        )\n",
    "\n",
    "    \n",
    "    if Marker==True:\n",
    "        latitudes = list(DataFrameInput.Longitude)\n",
    "        longitudes = list(DataFrameInput.Latitude)\n",
    "        labels = list(DataFrameInput.Station_Name)\n",
    "        for lat, lng, label in zip(latitudes, longitudes, labels):\n",
    "            folium.Marker([lat, lng], popup=label).add_to(MapInput)    \n",
    "    \n",
    "    \n",
    "    return buoys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available Data for each buoy\n",
    "Not all the buys have data available for the same period of time. Some have been working for a short period of time, some had worked before but not any more, and some of them recently started working and collecting data. To have a full collection of the time range of the data available for each buoy, the following page is used from National Data Buoy Center website:\n",
    "https://www.ndbc.noaa.gov/historical_data.shtml#stdmet. It is worth mentioning that we are only interested in Standard Meterological data. To have a better understanding of  Standard Meterological data, look at the information provided here: https://www.ndbc.noaa.gov/measdes.shtml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source=requests.get('https://www.ndbc.noaa.gov/historical_data.shtml').text\n",
    "soup = BeautifulSoup(source,'lxml')\n",
    "\n",
    "BuoyYearData={}\n",
    "BigTable=soup.find_all('ul')[1]\n",
    "SmallTable=BigTable.li.ul\n",
    "\n",
    "for indx,subtable in enumerate(SmallTable.find_all('li')):\n",
    "    StatName=SmallTable.find_all('li')[indx].text.split('\\n')[0].replace(':','')\n",
    "    est=SmallTable.find_all('li')[indx].text.split('\\n')\n",
    "    tmplist = est[1:]\n",
    "    for indx00,value in enumerate(tmplist):\n",
    "        tmplist[indx00] = tmplist[indx00].strip()\n",
    "    del tmplist[-1]\n",
    "    BuoyYearData[StatName]=tmplist\n",
    "    \n",
    "\n",
    "# Let's add one column for each year to the main dataframe\n",
    "YearsRange = range(1970,2019)\n",
    "df_full = df_full1.copy(deep=True)\n",
    "df_full.set_index(['Station_Name'],inplace=True)\n",
    "for indx, year in enumerate(YearsRange):\n",
    "    df_full[year] = None\n",
    "\n",
    "for indx,StName in enumerate(df_full.index):\n",
    "    first=np.array(df_full.loc[StName][4:].index).astype('int64')\n",
    "    try:\n",
    "        second=np.array(BuoyYearData[StName]).astype('int64')\n",
    "        df_full.loc[StName ,np.intersect1d(first,second)]=1\n",
    "    except:\n",
    "        df_full.loc[StName ,np.intersect1d(first,second)]=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the buoys with their corresponding owners\n",
    "figmp=folium.Figure(width=1300, height=700)\n",
    "WorldMap_map2 = folium.Map(location=[17.6078, -8.0817],tiles=\"Stamen Toner\",zoom_start=2).add_to(figmp)\n",
    "color=iter(plt.cm.rainbow(np.linspace(0,1,len(Owners))))\n",
    "for indx,owner in enumerate(Owners):\n",
    "    clr=matplotlib.colors.to_hex(next(color))\n",
    "    feature_group = folium.map.FeatureGroup(name=owner)\n",
    "    df_tmp = df_full1[df_full1['Owner']==owner]\n",
    "    buoys=BuoyLocationPlot2(feature_group,WorldMap_map2,df_tmp,clr,clr)\n",
    "    WorldMap_map2.add_child(buoys,name=owner,index=indx)\n",
    "    \n",
    "folium.TileLayer(\"Stamen Toner\").add_to(WorldMap_map2) \n",
    "folium.TileLayer(\"OpenStreetMap\").add_to(WorldMap_map2) \n",
    "folium.TileLayer(\"Stamen Terrain\").add_to(WorldMap_map2)\n",
    "WorldMap_map2.add_child(folium.map.LayerControl())\n",
    "WorldMap_map2.save(\"WorldMapBuoysOwners.html\")\n",
    "#WorldMap_map2.save(\"WorldMapBuoysOwners.eps\",format='eps') doesn't work!\n",
    "WorldMap_map2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. A look at the data <a class=\"anchor\" id=\"20\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the data for a specific buoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test Buoy: 46042 at Monterey Bay, California\n",
    "\n",
    "DumVar=\"No\"\n",
    "while DumVar==\"No\":\n",
    "    BName=input(\"Enter Buoy's name:\")\n",
    "    try:\n",
    "        print('Available annual data for this buoy:',BuoyYearData[BName])\n",
    "    except:\n",
    "        sys.exit('Error! There is no such buoy!!')\n",
    "    BYear=input(\"Year:\")\n",
    "    DumVar=\"Yes\" if ( df_full.loc[BName,int(BYear)]==1 ) else \"No\"\n",
    "    print(\"Is data for buoy {} availabale during year {}? {}\".format(BName,BYear,DumVar))\n",
    "    DumVar2=input('Do you want the data for the whole year? (Yes/No)')\n",
    "    if ( (DumVar2==\"No\" or DumVar2==\"no\") and (DumVar==\"Yes\") ):\n",
    "        startD=input('Enter the start date in the format DDMM like 10Jan: ')\n",
    "        endD=input('Enter the end date in the format DDMM like 25Dec: ')\n",
    "        date_start = startD+str(BYear)\n",
    "        date_end = endD+str(BYear)\n",
    "        date_st = datetime.strptime(date_start, \"%d%b%Y\")\n",
    "        date_en = datetime.strptime(date_end, \"%d%b%Y\")\n",
    "        print()\n",
    "        print('start date:',date_st)\n",
    "        print('end date:',date_en)\n",
    "\n",
    "print()\n",
    "print(\"Now, let's continue!\")\n",
    "print()\n",
    "url = \"https://www.ndbc.noaa.gov/view_text_file.php?filename={}h{}.txt.gz&dir=data/historical/stdmet/\".format(BName.lower(),BYear)\n",
    "print(\"Downloading the data ...\")\n",
    "print(url)\n",
    "df_BName = pd.read_csv(url,na_values=[99,999,9999],delim_whitespace=True, skiprows=range(1,2))\n",
    "print('Download is done!')\n",
    "\n",
    "\n",
    "# Concatonates (#YY MM DD hh mm) into one column as DATE\n",
    "df_BName.rename(columns={'#YY':'year','MM':'month','DD':'day','hh':'hour','mm':'minute'},inplace=True)\n",
    "df_BName['DATE']=pd.to_datetime(df_BName[['year', 'month', 'day','hour','minute']])\n",
    "df_BName.drop(columns=['year','month','day','hour','minute'],inplace=True)\n",
    "\n",
    "\n",
    "if (DumVar2==\"No\" or DumVar2==\"no\"):\n",
    "    df_BName=df_BName.loc[(df_BName['DATE']>=date_st) & (df_BName['DATE']<=date_en)]\n",
    "    df_BName.sort_values(by='DATE',ascending=False,inplace=True)\n",
    "    df_BName.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "listLabels = ['Wind Dir. (deg)', 'Wind speed (m/s)', 'Sign. Wave Height (m)', 'Domi. Wave Period (s)',\\\n",
    "              'Ave. Wave Period (s)','Wave Dir. (deg)', 'Sea Level Pressure (hPa)','Air Temp. (C)', 'Sea Surface Temp. (C)',\\\n",
    "              'Dewpoint Temp.','Station Visib. (nautical miles)','Water Level']\n",
    "df_BName.drop(columns=['GST'],inplace=True)\n",
    "\n",
    "#print(df_BName.head())\n",
    "df_BName=df_BName.dropna(axis=1, how=\"all\")\n",
    "df_BNameplt=df_BName.copy()\n",
    "print(df_BNameplt.columns)\n",
    "df_BNameplt.columns=['Wind Dir. (deg)', 'Wind speed (m/s)', 'Sign. Wave Height (m)', 'Domi. Wave Period (s)',\n",
    "                     'Ave. Wave Period (s)','Wave Dir. (deg)', 'Sea Level Pressure (hPa)','Air Temp. (C)', \n",
    "                     'Sea Surface Temp. (C)','Date']\n",
    "#print(df_BName.head())\n",
    "\n",
    "# Now, let's plot all the data we have\n",
    "print('Generating the plots ...')\n",
    "print()\n",
    "FNTSize = 25\n",
    "for indx,clmName in enumerate(df_BNameplt.columns[:-1]):\n",
    "    fig, axl1 = plt.subplots(1,1)\n",
    "    fig.set_size_inches(25, 5)\n",
    "    df_BNameplt.plot(kind='line',x='Date',y=clmName,fontsize=FNTSize,ax=axl1,legend=False,style='b-')\n",
    "    axl1.grid()\n",
    "    axl1.set_xlabel('Time',fontsize=FNTSize)\n",
    "    axl1.set_ylabel(clmName,fontsize=FNTSize)\n",
    "    plt.savefig('BuoyData_{}.eps'.format(df_BName.columns[indx]),format='eps',dpi=250, bbox_inches='tight')\n",
    "    fig.show()\n",
    "\n",
    "#A quick way to create new windrose axes...\n",
    "def new_axes():\n",
    "    fig = plt.figure(figsize=(8, 8), dpi=300, facecolor='w', edgecolor='w')\n",
    "    rect = [0.1, 0.1, 0.8, 0.8]\n",
    "    ax = WindroseAxes(fig, rect)\n",
    "    fig.add_axes(ax)\n",
    "    return ax\n",
    "\n",
    "#...and adjust the legend box\n",
    "def set_legend(ax):\n",
    "    l = ax.legend()\n",
    "    plt.setp(l.get_texts(), fontsize=FNTSize)\n",
    "    \n",
    "#FNTSize = 12\n",
    "if ('WDIR' in df_BName.columns and 'WSPD' in df_BName.columns):\n",
    "    theta = df_BName['WDIR'] * np.pi/180.0\n",
    "    r = df_BName['WSPD']\n",
    "    \n",
    "    ax = new_axes()\n",
    "    ax.bar(df_BName['WDIR'], r, normed=True, opening=0.8, edgecolor='white')\n",
    "    set_legend(ax)\n",
    "    ax.get_legend().get_title().set_fontsize('25')\n",
    "    \n",
    "    plt.savefig('WindRose.eps',format='eps',dpi=300, bbox_inches='tight')\n",
    "    fig.show()\n",
    "\n",
    "fig=plt.figure(figsize=(10, 8))\n",
    "#FNTSize = 12\n",
    "if ('MWD' in df_BName.columns and 'WVHT' in df_BName.columns):\n",
    "    theta = df_BName['MWD'] * np.pi/180.0\n",
    "    r = df_BName['WVHT']\n",
    "    \n",
    "    ax = new_axes()\n",
    "    ax.bar(df_BName['MWD'], r, normed=True, opening=0.9, edgecolor='white')\n",
    "    set_legend(ax)\n",
    "    ax.get_legend().get_title().set_fontsize('25')\n",
    "    \n",
    "    plt.savefig('WaveRose.eps', format='eps',dpi=300, bbox_inches='tight')\n",
    "    fig.show()\n",
    "    \n",
    "\n",
    "FNTSize = 30\n",
    "if ('WVHT' in df_BName.columns and 'APD' in df_BName.columns):\n",
    "    fig, (axf1, axf2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(20, 8)\n",
    "    #FNTSize = 17\n",
    "    # Frequency of frequencies and wave height\n",
    "    df_frq = df_BName[['APD']]\n",
    "    df_frq.columns=['FRQ']\n",
    "    df_frq.dropna(inplace=True)\n",
    "    count, bin_edges = np.histogram(df_frq)\n",
    "\n",
    "    sigma, mu = df_frq.std(), df_frq.mean()\n",
    "    mu.FRQ = round(mu.FRQ,2)\n",
    "    sigma.FRQ = round(sigma.FRQ,2)\n",
    "    df_frq.plot(kind='hist', bins=40 , normed=True,ax=axf1,fontsize=FNTSize,legend=False,colormap='winter')\n",
    "    axf1.set_xlabel('Time Period (s)',fontsize=FNTSize)\n",
    "    axf1.set_ylabel('Occurance',fontsize=FNTSize)\n",
    "    axf1.text(10, 0.15, r'$\\mu={},\\ \\sigma={}$'.format(mu.FRQ,sigma.FRQ),{'color': 'black', 'fontsize': 25, 'ha': 'left', 'va': 'center', 'bbox': dict(boxstyle=\"round\", fc=\"white\", ec=\"black\", pad=0.2)})\n",
    "    axf1.grid()\n",
    "\n",
    "    sigma, mu = df_BName[['WVHT']].std(), df_BName[['WVHT']].mean()\n",
    "    mu.FRQ = round(mu.WVHT,2)\n",
    "    sigma.FRQ = round(sigma.WVHT,2)\n",
    "    df_BName[['WVHT']].plot(kind='hist',bins=40, normed=True,ax=axf2,fontsize=FNTSize,legend=False,colormap='winter')\n",
    "    axf2.set_xlabel('Ave. Wave Height (m)',fontsize=FNTSize)\n",
    "    axf2.set_ylabel('Occurance',fontsize=FNTSize)\n",
    "    axf2.text(4, 0.3, r'$\\mu={},\\ \\sigma={}$'.format(mu.FRQ,sigma.FRQ),{'color': 'black', 'fontsize': 25, 'ha': 'left', 'va': 'center', 'bbox': dict(boxstyle=\"round\", fc=\"white\", ec=\"black\", pad=0.2)})\n",
    "    axf2.grid()\n",
    "    \n",
    "    plt.savefig('Occurance.eps', format='eps',dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
